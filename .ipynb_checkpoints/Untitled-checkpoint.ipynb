{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "class Param():\n",
    "    def __init__(self):\n",
    "        # General parameters\n",
    "        self.train = 1 # Train the model\n",
    "        self.sample = 0 # Sample from the model\n",
    "        self.rnn_size = 256 # Size of RNN hidden state\n",
    "        self.tsteps = 150 # RNN time steps (for backprop)\n",
    "        self.nmixtures = 20 # Number of gaussian mixtures\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = 64 # Batch size for each gradient step\n",
    "        self.nbatches = 500 # Number of batches per epoch, default is 500\n",
    "        self.nepochs = 100 # Number of epochs, default is 250\n",
    "        self.dropout = 0.95 # Probability of keeping neuron during dropout\n",
    "        self.grad_clip = 10. # Clip gradients to this magnitude, default 10\n",
    "        self.optimizer = 'rmsprop' # Ctype of optimizer: 'rmsprop' or 'adam'\n",
    "        self.learning_rate = 1e-4 # Learning rate\n",
    "        self.lr_decay = 1. # Decay rate for learning rate\n",
    "        self.decay = 0.95 # Decay rate for rmsprop\n",
    "        self.momentum = 0.9 # Momentum for rmsprop\n",
    "\n",
    "        # Window parmaters\n",
    "        self.kmixtures = 1 # Number of gaussian mixtures for character window\n",
    "        self.alphabet = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' # Default is a-z, A-Z, space, and <UNK> tag\n",
    "        self.tsteps_per_ascii = 25 # Expected number of pen points per character\n",
    "\n",
    "        # Book-saving\n",
    "        self.data_scale = 50 # Amount to scale data down before training\n",
    "        self.log_dir ='./logs/' # Location, relative to execution, of log files\n",
    "        self.data_dir ='./data' # Location, relative to execution, of data\n",
    "        self.save_path ='saved/model.ckpt' # Location to save model\n",
    "        self.save_every = 2000 # Number of batches between each save\n",
    "\n",
    "        # Sampling\n",
    "        self.text ='' # String for sampling model (defaults to test cases)\n",
    "        self.style =-1 # Optionally condition model on a preset style (using data in styles.p)\n",
    "        self.bias = 1.0 # Higher bias means neater, lower means more diverse (range is 0-5)\n",
    "        self.sleep_time=60*5 # Time to sleep between running sampler\n",
    "        \n",
    "args = Param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING MODE...\n",
      "<__main__.Param object at 0x000002ACAE59E588>\n",
      "\n",
      "loading data...\n",
      "\tloaded dataset:\n",
      "\t\t11315 train individual data points\n",
      "\t\t595 valid individual data points\n",
      "\t\t176 batches\n",
      "building model...\n",
      "\tusing alphabet abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "logger = Logger(args) # make logging utility\n",
    "logger.write(\"\\nTRAINING MODE...\")\n",
    "logger.write(\"{}\\n\".format(args))\n",
    "logger.write(\"loading data...\")\n",
    "data_loader = DataLoader(args, logger=logger)\n",
    "\n",
    "logger.write(\"building model...\")\n",
    "model = Model(args, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt to load saved model...\n",
      "INFO:tensorflow:Restoring parameters from saved\\model.ckpt-900\n",
      "loaded model: saved\\model.ckpt-900\n",
      "training...\n",
      "learning rate: 9.999999747378752e-05\n",
      "910/50000, loss = 1.107, regloss = 0.11116, valid_loss = 1.071, time = 0.172\n",
      "920/50000, loss = 0.876, regloss = 0.19713, valid_loss = 1.069, time = 0.156\n",
      "930/50000, loss = 0.984, regloss = 0.27658, valid_loss = 1.071, time = 0.156\n",
      "940/50000, loss = 0.926, regloss = 0.35068, valid_loss = 1.067, time = 0.156\n",
      "950/50000, loss = 1.027, regloss = 0.41355, valid_loss = 1.068, time = 0.172\n",
      "960/50000, loss = 1.004, regloss = 0.47199, valid_loss = 1.069, time = 0.156\n",
      "970/50000, loss = 1.030, regloss = 0.52614, valid_loss = 1.067, time = 0.156\n",
      "980/50000, loss = 1.204, regloss = 0.57640, valid_loss = 1.063, time = 0.156\n",
      "990/50000, loss = 1.010, regloss = 0.61940, valid_loss = 1.061, time = 0.156\n",
      "learning rate: 9.999999747378752e-05\n",
      "SAVED MODEL.\n",
      "The total time of training is: 136.13173413276672 s.\n",
      "1000/50000, loss = 1.008, regloss = 0.65643, valid_loss = 1.060, time = 0.234\n",
      "1010/50000, loss = 0.922, regloss = 0.69246, valid_loss = 1.058, time = 0.188\n",
      "1020/50000, loss = 1.005, regloss = 0.72124, valid_loss = 1.056, time = 0.156\n",
      "1030/50000, loss = 1.142, regloss = 0.75289, valid_loss = 1.055, time = 0.156\n",
      "1040/50000, loss = 1.161, regloss = 0.78137, valid_loss = 1.052, time = 0.172\n",
      "1050/50000, loss = 1.187, regloss = 0.80560, valid_loss = 1.051, time = 0.156\n",
      "1060/50000, loss = 0.878, regloss = 0.82521, valid_loss = 1.046, time = 0.172\n",
      "1070/50000, loss = 1.109, regloss = 0.84270, valid_loss = 1.045, time = 0.156\n",
      "1080/50000, loss = 0.982, regloss = 0.85672, valid_loss = 1.041, time = 0.156\n",
      "1090/50000, loss = 0.939, regloss = 0.87166, valid_loss = 1.036, time = 0.172\n",
      "SAVED MODEL.\n",
      "The total time of training is: 153.0544490814209 s.\n",
      "1100/50000, loss = 0.930, regloss = 0.88174, valid_loss = 1.033, time = 0.172\n",
      "1110/50000, loss = 0.893, regloss = 0.88924, valid_loss = 1.029, time = 0.172\n",
      "1120/50000, loss = 1.133, regloss = 0.89713, valid_loss = 1.021, time = 0.172\n",
      "1130/50000, loss = 0.989, regloss = 0.90641, valid_loss = 1.018, time = 0.172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6708d66c50ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_seq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_kappa\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkappa\u001b[0m\u001b[1;33m,\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mfeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mfeed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_kappa\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkmixtures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.write(\"attempt to load saved model...\")\n",
    "load_was_success, global_step = model.try_load_model(args.save_path)\n",
    "\n",
    "v_x, v_y, v_s, v_c = data_loader.validation_data()\n",
    "valid_inputs = {model.input_data: v_x, model.target_data: v_y, model.char_seq: v_c}\n",
    "\n",
    "logger.write(\"training...\")\n",
    "model.sess.run(tf.assign(model.decay, args.decay ))\n",
    "model.sess.run(tf.assign(model.momentum, args.momentum ))\n",
    "running_average = 0.0 ; remember_rate = 0.99\n",
    "training_time = time.time() # Used to compute global training time of the model\n",
    "\n",
    "for e in range(int(global_step/args.nbatches), args.nepochs):\n",
    "    model.sess.run(tf.assign(model.learning_rate, args.learning_rate * (args.lr_decay ** e)))\n",
    "    logger.write(\"learning rate: {}\".format(model.learning_rate.eval()))\n",
    "\n",
    "    c0, c1, c2 = model.istate_cell0.c.eval(), model.istate_cell1.c.eval(), model.istate_cell2.c.eval()\n",
    "    h0, h1, h2 = model.istate_cell0.h.eval(), model.istate_cell1.h.eval(), model.istate_cell2.h.eval()\n",
    "    kappa = np.zeros((args.batch_size, args.kmixtures, 1))\n",
    "\n",
    "    for b in range(global_step%args.nbatches, args.nbatches):\n",
    "\n",
    "        i = e * args.nbatches + b\n",
    "        if global_step is not 0 : i+=1 ; global_step = 0\n",
    "\n",
    "        if i % args.save_every == 0 and (i > 0):\n",
    "            model.time = model.time + time.time() - training_time\n",
    "            model.saver.save(model.sess, args.save_path, global_step = i) ; \n",
    "            logger.write('SAVED MODEL.')\n",
    "            training_time = time.time()\n",
    "            print(\"The total time of training is:\",model.time,\"s.\")\n",
    "            \n",
    "        start = time.time()\n",
    "        x, y, s, c = data_loader.next_batch()\n",
    "\n",
    "        feed = {model.input_data: x, model.target_data: y, model.char_seq: c, model.init_kappa: kappa, \\\n",
    "            model.istate_cell0.c: c0, model.istate_cell1.c: c1, model.istate_cell2.c: c2, \\\n",
    "            model.istate_cell0.h: h0, model.istate_cell1.h: h1, model.istate_cell2.h: h2}\n",
    "\n",
    "        [train_loss, _] = model.sess.run([model.cost, model.train_op], feed)\n",
    "        feed.update(valid_inputs)\n",
    "        feed[model.init_kappa] = np.zeros((args.batch_size, args.kmixtures, 1))\n",
    "        [valid_loss] = model.sess.run([model.cost], feed)\n",
    "\n",
    "        running_average = running_average*remember_rate + train_loss*(1-remember_rate)\n",
    "\n",
    "        end = time.time()\n",
    "        if i % 10 is 0: logger.write(\"{}/{}, loss = {:.3f}, regloss = {:.5f}, valid_loss = {:.3f}, time = {:.3f}\" \\\n",
    "            .format(i, args.nepochs * args.nbatches, train_loss, running_average, valid_loss, end - start))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
